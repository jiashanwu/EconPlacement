{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running all webscrapping scripts\n",
    "Importing moduels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "from requests import get\n",
    "from requests.exceptions import RequestException\n",
    "from contextlib import closing\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file placement_univ_acronym contains info like: full name of each university; the location; ranks from usnews; links of econ placement; some other notes; acronyms of each university."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>university</th>\n",
       "      <th>place</th>\n",
       "      <th>usnews</th>\n",
       "      <th>link</th>\n",
       "      <th>note</th>\n",
       "      <th>acronym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Harvard University</td>\n",
       "      <td>Cambridge, MA</td>\n",
       "      <td>#1 in Economics (tie)</td>\n",
       "      <td>https://economics.harvard.edu/placement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>harvard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Massachusetts Institute of Technology</td>\n",
       "      <td>Cambridge, MA</td>\n",
       "      <td>#1 in Economics (tie)</td>\n",
       "      <td>https://economics.mit.edu/graduate/career</td>\n",
       "      <td>pdf</td>\n",
       "      <td>mit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Princeton University</td>\n",
       "      <td>Princeton , NJ</td>\n",
       "      <td>#1 in Economics (tie)</td>\n",
       "      <td>https://economics.princeton.edu/graduate-progr...</td>\n",
       "      <td>pdf</td>\n",
       "      <td>princeton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stanford University</td>\n",
       "      <td>Stanford, CA</td>\n",
       "      <td>#1 in Economics (tie)</td>\n",
       "      <td>https://economics.stanford.edu/graduate/studen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stanford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>University of California--Berkeley</td>\n",
       "      <td>Berkeley, CA</td>\n",
       "      <td>#1 in Economics (tie)</td>\n",
       "      <td>https://www.econ.berkeley.edu/grad/program/pla...</td>\n",
       "      <td>noname</td>\n",
       "      <td>berkley</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              university           place  \\\n",
       "0                     Harvard University   Cambridge, MA   \n",
       "1  Massachusetts Institute of Technology   Cambridge, MA   \n",
       "2                   Princeton University  Princeton , NJ   \n",
       "3                    Stanford University    Stanford, CA   \n",
       "4     University of California--Berkeley    Berkeley, CA   \n",
       "\n",
       "                  usnews                                               link  \\\n",
       "0  #1 in Economics (tie)            https://economics.harvard.edu/placement   \n",
       "1  #1 in Economics (tie)          https://economics.mit.edu/graduate/career   \n",
       "2  #1 in Economics (tie)  https://economics.princeton.edu/graduate-progr...   \n",
       "3  #1 in Economics (tie)  https://economics.stanford.edu/graduate/studen...   \n",
       "4  #1 in Economics (tie)  https://www.econ.berkeley.edu/grad/program/pla...   \n",
       "\n",
       "     note    acronym  \n",
       "0     NaN    harvard  \n",
       "1     pdf        mit  \n",
       "2     pdf  princeton  \n",
       "3     NaN   stanford  \n",
       "4  noname    berkley  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = pd.read_excel(\"placement_univ_acronym.xlsx\")\n",
    "links.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to use in webscrapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_get(url):\n",
    "    \"\"\"\n",
    "    Attempts to get the content at `url` by making an HTTP GET request.\n",
    "    If the content-type of response is some kind of HTML/XML, return the\n",
    "    text content, otherwise return None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with closing(get(url, stream=True)) as resp:\n",
    "            if is_good_response(resp):\n",
    "                return resp.content\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "    except RequestException as e:\n",
    "        log_error('Error during requests to {0} : {1}'.format(url, str(e)))\n",
    "        return None\n",
    "    \n",
    "def is_good_response(resp):\n",
    "    \"\"\"\n",
    "    Returns True if the response seems to be HTML, False otherwise.\n",
    "    \"\"\"\n",
    "    content_type = resp.headers['Content-Type'].lower()\n",
    "    return (resp.status_code == 200 \n",
    "            and content_type is not None \n",
    "            and content_type.find('html') > -1)\n",
    "\n",
    "\n",
    "def log_error(e):\n",
    "    \"\"\"\n",
    "    It is always a good idea to log errors. \n",
    "    This function just prints them, but you can\n",
    "    make it do anything.\n",
    "    \"\"\"\n",
    "    print(e)\n",
    "    \n",
    "def find_pattern(s, srt, end):\n",
    "    \n",
    "    pattern = r'(?<=' + srt + ').*(?=' + end + ')'\n",
    "    name_pattern = re.compile(pattern, flags = re.M)\n",
    "    names = name_pattern.findall(s)\n",
    "    \n",
    "    return(names)\n",
    "\n",
    "def assign_year(s, names, year):\n",
    "    \n",
    "    name_idx = [s.find(i) for i in names]\n",
    "    year_idx = [s.find(i) for i in year]\n",
    "\n",
    "    year_idx.append(len(s))\n",
    "    name_year = []\n",
    "\n",
    "    for i in name_idx:\n",
    "        name_year.extend([year[j] for j in range(len(year_idx)) if i >= year_idx[j] and i < year_idx[j + 1]])\n",
    "        \n",
    "    return(name_year)\n",
    "\n",
    "def fast_parse_1(html, name_parser, placement_parser, year_parser):\n",
    "    \n",
    "    # print(html)\n",
    "\n",
    "    # read the content of the placement website\n",
    "    raw_html = simple_get(html)\n",
    "    html = BeautifulSoup(raw_html, 'html.parser')\n",
    "\n",
    "    # store the year and placement info\n",
    "    names = []\n",
    "    year = []\n",
    "    fileds = []\n",
    "    placement = []\n",
    "\n",
    "    s = str(html)\n",
    "    \n",
    "    srt, end = placement_parser\n",
    "    placement = find_pattern(s, srt, end)\n",
    "    # print('Length of placement list: {}'.format(len(placement)))\n",
    "\n",
    "    if name_parser != [None, None]:\n",
    "        srt, end = name_parser\n",
    "        names = find_pattern(s, srt, end)\n",
    "        # print('Length of name list: {}'.format(len(names)))\n",
    "    else:\n",
    "        names = [None] * len(placement)\n",
    "        \n",
    "        srt, end = year_parser\n",
    "        year = find_pattern(s, srt, end)\n",
    "        year_new = [srt + i for i in year]\n",
    "\n",
    "        name_year = assign_year(s, placement, year_new)\n",
    "        name_year = [i.replace(srt, '') for i in name_year]\n",
    "\n",
    "        tmp = [[name_year[i], names[i], placement[i]] for i in range(len(name_year))]\n",
    "        tmp = pd.DataFrame(tmp)\n",
    "        tmp.columns = ['Year', 'Name', 'Placement']\n",
    "\n",
    "        return(tmp)\n",
    "    \n",
    "    if len(names) == len(placement):\n",
    "\n",
    "        srt, end = year_parser\n",
    "        year = find_pattern(s, srt, end)\n",
    "        year_new = [srt + i for i in year]\n",
    "\n",
    "        name_year = assign_year(s, names, year_new)\n",
    "        name_year = [i.replace(srt, '') for i in name_year]\n",
    "\n",
    "        tmp = [[name_year[i], names[i], placement[i]] for i in range(len(name_year))]\n",
    "        tmp = pd.DataFrame(tmp)\n",
    "        tmp.columns = ['Year', 'Name', 'Placement']\n",
    "\n",
    "        return(tmp)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        return([placement, names])\n",
    "    \n",
    "def fast_parse_2(html, name_parser, placement_parser, year_parser):\n",
    "    \n",
    "    # print(html)\n",
    "\n",
    "    # read the content of the placement website\n",
    "    raw_html = simple_get(html)\n",
    "    html = BeautifulSoup(raw_html, 'html.parser')\n",
    "\n",
    "    # store the year and placement info\n",
    "    names = []\n",
    "    year = []\n",
    "    placement = []\n",
    "\n",
    "    s = str(html)\n",
    "    \n",
    "    srt, end = placement_parser\n",
    "    placement = find_pattern(s, srt, end)\n",
    "    # print('Length of placement list: {}'.format(len(placement)))\n",
    "    \n",
    "    srt, end = name_parser\n",
    "    names = find_pattern(s, srt, end)\n",
    "    # print('Length of name list: {}'.format(len(names)))\n",
    "   \n",
    "    srt, end = year_parser\n",
    "    year = find_pattern(s, srt, end)\n",
    "    # print('Length of year list: {}'.format(len(year)))\n",
    "    \n",
    "    if len(names) == len(placement) and len(names) == len(year):\n",
    "\n",
    "        tmp = [[year[i], names[i], placement[i]] for i in range(len(names))]\n",
    "        tmp = pd.DataFrame(tmp)\n",
    "        tmp.columns = ['Year', 'Name', 'Placement']\n",
    "\n",
    "        return(tmp)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        return([placement, names, year])\n",
    "    \n",
    "    \n",
    "def print_out_html(html):\n",
    "    \n",
    "    # print(html)\n",
    "\n",
    "    # read the content of the placement website\n",
    "    raw_html = simple_get(html)\n",
    "    html = BeautifulSoup(raw_html, 'html.parser')\n",
    "\n",
    "    s = str(html)\n",
    "    \n",
    "    return(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each university with a valid webscrapping scripts, save the econ placement csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing university: american\n",
      "Processing university: bc\n",
      "Processing university: bu\n",
      "Processing university: clemson\n",
      "Processing university: columbia\n",
      "Processing university: cub\n",
      "Processing university: duke\n",
      "Processing university: fsu\n",
      "Processing university: gsu\n",
      "Processing university: harvard\n",
      "Processing university: iub\n",
      "Processing university: lsu\n",
      "Processing university: missouri\n",
      "Processing university: msu\n",
      "Processing university: nyu\n",
      "Processing university: stanford\n",
      "Processing university: ucb\n",
      "Processing university: uci\n",
      "Processing university: ucla\n",
      "Processing university: uconn\n",
      "Processing university: ucsd\n",
      "Processing university: uh\n",
      "Processing university: uiuc\n",
      "Processing university: ukansas\n",
      "Processing university: uky\n",
      "Processing university: umn\n",
      "Processing university: upenn\n",
      "Processing university: uta\n",
      "Processing university: utah\n",
      "Processing university: utk\n",
      "Processing university: uva\n",
      "Processing university: vandy\n",
      "Processing university: vt\n"
     ]
    }
   ],
   "source": [
    "# acquire the file directory and all websrapping scripts\n",
    "for (dirpath, dirnames, filenames) in os.walk('websracp_univ'):  \n",
    "    dr, fn_li = dirpath, filenames\n",
    "    \n",
    "for fn in fn_li:\n",
    "    \n",
    "    str_command = \"exec(open('\" + str(dirpath) + \"//\" + str(fn) + \"').read())\"\n",
    "    exec(str_command)\n",
    "    \n",
    "    univ = fn.split('.')[0]\n",
    "    print('Processing university: {}'.format(univ))\n",
    "    str_command = str(univ) + \"['Acronym'] = '\" + str(univ) + \"'\" \n",
    "    exec(str_command)\n",
    "    \n",
    "    str_command = str(univ) + \".to_csv('data_by_univ//\" + str(univ) + \".csv', index = False)\" \n",
    "    exec(str_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all saved csvs into one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of obs: 4196\n"
     ]
    }
   ],
   "source": [
    "for (dirpath, dirnames, filenames) in os.walk('data_by_univ'):  \n",
    "    dr, fn_li = dirpath, filenames\n",
    "    \n",
    "df = pd.DataFrame()\n",
    "\n",
    "for fn in fn_li:    \n",
    "    str_command = \"df1 = pd.read_csv('\" + str(dirpath) + \"//\" + str(fn) + \"')\"\n",
    "    exec(str_command)\n",
    "    # print(str_command)\n",
    "    # print(df1.columns)\n",
    "    df = df.append(df1)\n",
    "    \n",
    "print('Number of obs: {}'.format(len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the combined placement dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_date = True\n",
    "\n",
    "if add_date:\n",
    "    filename = 'data//data' + datetime.today().strftime('%Y-%m-%d') + '.csv'\n",
    "else:\n",
    "    filename = \"data//data.csv\"\n",
    "\n",
    "df.to_csv(filename, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a list of universities contained in our sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['american', 'bc', 'bu', 'clemson', 'columbia', 'cub', 'duke',\n",
       "       'fsu', 'gsu', 'harvard', 'iub', 'lsu', 'missouri', 'msu', 'nyu',\n",
       "       'stanford', 'ucb', 'uci', 'ucla', 'uconn', 'ucsd', 'uh', 'uiuc',\n",
       "       'ukansas', 'uky', 'umn', 'upenn', 'uta', 'utah', 'utk', 'uva',\n",
       "       'vandy', 'vt'], dtype=object)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Acronym'].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
